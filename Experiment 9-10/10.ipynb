{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c31705f8-41be-4200-9346-d9ca5f168dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c42bafa-c3fd-4fa3-b409-4780d3440e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [ \n",
    "    'poi-1.5.csv', \n",
    "    'poi-2.0.csv', \n",
    "    'poi-2.5.csv', \n",
    "    'poi-3.0.csv',\n",
    "    'velocity-1.4.csv',\n",
    "    'velocity-1.5.csv',\n",
    "    'velocity-1.6.csv',\n",
    "    'lucene-2.0.csv', \n",
    "    'lucene-2.2.csv', \n",
    "    'lucene-2.4.csv',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38852d17-7990-4cdd-83ed-660a4a50f900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisionTree(X,y):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X=scaler.transform(X)\n",
    "    X=pd.DataFrame(X)\n",
    "    features=X\n",
    "    label=y\n",
    "    #print(X)\n",
    "    # instantiate the model (using the default parameters)\n",
    "    dtreeclf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
    "    \n",
    "    scores = cross_validate(\n",
    "        estimator=dtreeclf, # model to evaluate\n",
    "        X=features, # inputs features\n",
    "        y=label, # output labels\n",
    "        cv=10, # how many folds\n",
    "        # list of model evaluation metrics\n",
    "        scoring=['accuracy', 'precision', 'recall'],\n",
    "    )\n",
    "\n",
    "    scores = pd.DataFrame(scores)\n",
    "    scores.round(4)\n",
    "    scores.mean().round(4)\n",
    "    return scores.mean()['test_recall']\n",
    "\n",
    "def logisticClassifier(X,y):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X=scaler.transform(X)\n",
    "    X=pd.DataFrame(X)\n",
    "    features=X\n",
    "    label=y\n",
    "    #print(X)\n",
    "    # instantiate the model (using the default parameters)\n",
    "    logreg = LogisticRegression(random_state=16)\n",
    "    \n",
    "    scores = cross_validate(\n",
    "        estimator=logreg, # model to evaluate\n",
    "        X=features, # inputs features\n",
    "        y=label, # output labels\n",
    "        cv=10, # how many folds\n",
    "        # list of model evaluation metrics\n",
    "        scoring=['accuracy', 'precision', 'recall'],\n",
    "    )\n",
    "    \n",
    "    scores = pd.DataFrame(scores)\n",
    "    scores.round(4)\n",
    "    scores.mean().round(4)\n",
    "    return scores.mean()['test_recall']\n",
    "\n",
    "def naiveBayesClassifier(X,y):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X=scaler.transform(X)\n",
    "    X=pd.DataFrame(X)\n",
    "    features=X\n",
    "    label=y\n",
    "    \n",
    "    # instantiate the model (using the default parameters)\n",
    "    NBclf = GaussianNB()\n",
    "    scores = cross_validate(\n",
    "        estimator=NBclf,  # model to evaluate\n",
    "        X=features,  # input features\n",
    "        y=label,  # output labels\n",
    "        cv=10,  # how many folds\n",
    "        # list of model evaluation metrics\n",
    "        scoring=['accuracy', 'precision', 'recall'],\n",
    "    )\n",
    "\n",
    "    scores = pd.DataFrame(scores)\n",
    "    scores.round(4)\n",
    "    scores.mean().round(4)\n",
    "    return scores.mean()['test_recall']\n",
    "\n",
    "def randomForest(X,y):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X=scaler.transform(X)\n",
    "    X=pd.DataFrame(X)\n",
    "    features=X\n",
    "    label=y\n",
    "    rfclassifier = RandomForestClassifier(random_state=59, n_jobs=-1, max_depth=5,\n",
    "    n_estimators=100, oob_score=True)\n",
    "    \n",
    "    scores = cross_validate(\n",
    "        estimator=rfclassifier, # model to evaluate\n",
    "        X=features, # inputs features\n",
    "        y=label, # output labels\n",
    "        cv=10, # how many folds\n",
    "        # list of model evaluation metrics\n",
    "        scoring=['accuracy', 'recall'],\n",
    "    )\n",
    "    \n",
    "    scores = pd.DataFrame(scores)\n",
    "    scores.round(4)\n",
    "    scores.mean().round(4)\n",
    "    return scores.mean()['test_recall']\n",
    "\n",
    "def knnClassifier(X, y):\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # Check data contiguity\n",
    "    if not X.flags.c_contiguous:\n",
    "        X = np.ascontiguousarray(X)\n",
    "    if not y.flags.c_contiguous:\n",
    "        y = np.ascontiguousarray(y)\n",
    "        \n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn.fit(X, y)\n",
    "    y_pred = knn.predict(X)\n",
    "    recall = metrics.recall_score(y, y_pred)\n",
    "    return recall\n",
    "\n",
    "\n",
    "def svmClassifier(X,y):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X=scaler.transform(X)\n",
    "    X=pd.DataFrame(X)\n",
    "    features=X\n",
    "    label=y\n",
    "    \n",
    "    # instantiate the model (using the default parameters)\n",
    "    svmclf = svm.SVC(kernel='linear', C=1, random_state=0)\n",
    "    scores = cross_validate(\n",
    "        estimator=svmclf,  # model to evaluate\n",
    "        X=features,  # input features\n",
    "        y=label,  # output labels\n",
    "        cv=10,  # how many folds\n",
    "        # list of model evaluation metrics\n",
    "        scoring=['accuracy','precision' , 'recall'],\n",
    "    )\n",
    "\n",
    "    scores = pd.DataFrame(scores)\n",
    "    scores.round(4)\n",
    "    scores.mean().round(4)\n",
    "    return scores.mean()['test_recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e39d17c1-614d-4e3a-a870-3838b918ed98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp5(dataset):\n",
    "    df = pd.read_csv(\"../dataset/\" + dataset)\n",
    "    df.dropna(inplace=True)\n",
    "    # print(f\"Dataset: {dataset} with shape {df.shape}\")\n",
    "    y = df.iloc[:,-1]\n",
    "    X = df.iloc[:,:-1]\n",
    "    \n",
    "    recall_scores = {\n",
    "        'Decision Tree': decisionTree(X, y),\n",
    "        'Logistic Regression': logisticClassifier(X, y),\n",
    "        'Naive Bayes': naiveBayesClassifier(X, y),\n",
    "        'Random Forest': randomForest(X, y),\n",
    "        'K-NN': knnClassifier(X, y),\n",
    "        'SVM': svmClassifier(X, y)\n",
    "    }\n",
    "    \n",
    "    return recall_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1455568f-2e92-4100-bd5f-84ebfd5f256f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Decision Tree  Logistic Regression  Naive Bayes  Random Forest      K-NN       SVM\n",
      "poi-1.5.csv            0.766667             0.815714     0.310952       0.850952  0.801418  0.794286\n",
      "poi-2.0.csv            1.000000             1.000000     1.000000       1.000000  0.135135  1.000000\n",
      "poi-2.5.csv            0.878833             0.850167     0.335667       0.879333  0.907258  0.834167\n",
      "poi-3.0.csv            1.000000             1.000000     1.000000       1.000000  0.903915  1.000000\n",
      "velocity-1.4.csv       1.000000             1.000000     1.000000       1.000000  0.945578  1.000000\n",
      "velocity-1.5.csv       0.723810             0.866190     0.311429       0.880000  0.901408  0.844762\n",
      "velocity-1.6.csv       0.546429             0.471429     0.271429       0.523214  0.602564  0.444643\n",
      "lucene-2.0.csv         1.000000             0.878889     1.000000       1.000000  0.703297  1.000000\n",
      "lucene-2.2.csv         0.696190             0.756667     0.400952       0.819524  0.868056  0.854286\n",
      "lucene-2.4.csv         1.000000             0.971190     1.000000       1.000000  0.871921  1.000000\n"
     ]
    }
   ],
   "source": [
    "result_df = pd.DataFrame()\n",
    "\n",
    "# Iterate over each dataset\n",
    "for dataset in datasets:\n",
    "    recall_scores = exp5(dataset)\n",
    "    df = pd.DataFrame.from_dict(recall_scores, orient='index', columns=[dataset])\n",
    "    result_df = pd.concat([result_df, df], axis=1)\n",
    "\n",
    "result_df = result_df.T\n",
    "print(result_df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "447f8343-a323-41e3-b899-10329c53aed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------------+-----------------------+---------------+-----------------+----------+----------+\n",
      "|                  |   Decision Tree |   Logistic Regression |   Naive Bayes |   Random Forest |     K-NN |      SVM |\n",
      "+==================+=================+=======================+===============+=================+==========+==========+\n",
      "| poi-1.5.csv      |        0.766667 |              0.815714 |      0.310952 |        0.850952 | 0.801418 | 0.794286 |\n",
      "+------------------+-----------------+-----------------------+---------------+-----------------+----------+----------+\n",
      "| poi-2.0.csv      |        1        |              1        |      1        |        1        | 0.135135 | 1        |\n",
      "+------------------+-----------------+-----------------------+---------------+-----------------+----------+----------+\n",
      "| poi-2.5.csv      |        0.878833 |              0.850167 |      0.335667 |        0.879333 | 0.907258 | 0.834167 |\n",
      "+------------------+-----------------+-----------------------+---------------+-----------------+----------+----------+\n",
      "| poi-3.0.csv      |        1        |              1        |      1        |        1        | 0.903915 | 1        |\n",
      "+------------------+-----------------+-----------------------+---------------+-----------------+----------+----------+\n",
      "| velocity-1.4.csv |        1        |              1        |      1        |        1        | 0.945578 | 1        |\n",
      "+------------------+-----------------+-----------------------+---------------+-----------------+----------+----------+\n",
      "| velocity-1.5.csv |        0.72381  |              0.86619  |      0.311429 |        0.88     | 0.901408 | 0.844762 |\n",
      "+------------------+-----------------+-----------------------+---------------+-----------------+----------+----------+\n",
      "| velocity-1.6.csv |        0.546429 |              0.471429 |      0.271429 |        0.523214 | 0.602564 | 0.444643 |\n",
      "+------------------+-----------------+-----------------------+---------------+-----------------+----------+----------+\n",
      "| lucene-2.0.csv   |        1        |              0.878889 |      1        |        1        | 0.703297 | 1        |\n",
      "+------------------+-----------------+-----------------------+---------------+-----------------+----------+----------+\n",
      "| lucene-2.2.csv   |        0.69619  |              0.756667 |      0.400952 |        0.819524 | 0.868056 | 0.854286 |\n",
      "+------------------+-----------------+-----------------------+---------------+-----------------+----------+----------+\n",
      "| lucene-2.4.csv   |        1        |              0.97119  |      1        |        1        | 0.871921 | 1        |\n",
      "+------------------+-----------------+-----------------------+---------------+-----------------+----------+----------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "print(tabulate(result_df, headers='keys', tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5fedbe6-f97f-4a29-b894-c55ec196b318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mann-Whitney U-test statistic: 1221.0, p-value: 1.6140451335993335e-06\n",
      "There is a significant difference between DIT and NOC.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "uims_df = pd.read_csv(\"../dataset/UIMS.csv\")\n",
    "# print(uims_df)\n",
    "dit = uims_df['dit'].tolist()\n",
    "noc = uims_df['noc'].tolist()\n",
    "\n",
    "stat, p_value = mannwhitneyu(dit, noc)\n",
    "print(f\"Mann-Whitney U-test statistic: {stat}, p-value: {p_value}\")\n",
    "\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"There is a significant difference between DIT and NOC.\")\n",
    "else:\n",
    "    print(\"There is no significant difference between DIT and NOCs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "971dfc43-51fe-4179-9445-b365a96a8852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wilcoxon signed-rank test statistic: 21.0, p-value: 0.556640625\n",
      "            Dataset  ML1 Logistic Regression (Recall)  \\\n",
      "0       poi-1.5.csv                          0.815714   \n",
      "1       poi-2.0.csv                          1.000000   \n",
      "2       poi-2.5.csv                          0.850167   \n",
      "3       poi-3.0.csv                          1.000000   \n",
      "4  velocity-1.4.csv                          1.000000   \n",
      "5  velocity-1.5.csv                          0.866190   \n",
      "6  velocity-1.6.csv                          0.471429   \n",
      "7    lucene-2.0.csv                          0.878889   \n",
      "8    lucene-2.2.csv                          0.756667   \n",
      "9    lucene-2.4.csv                          0.971190   \n",
      "\n",
      "   ML2 K-NN Classifier (Recall)        di   Abs(di)  rank  \n",
      "0                      0.801418  0.014296  0.014296   1.0  \n",
      "1                      0.135135  0.864865  0.864865  10.0  \n",
      "2                      0.907258 -0.057091  0.057091   4.0  \n",
      "3                      0.903915  0.096085  0.096085   5.0  \n",
      "4                      0.945578  0.054422  0.054422   3.0  \n",
      "5                      0.901408 -0.035218  0.035218   2.0  \n",
      "6                      0.602564 -0.131136  0.131136   8.0  \n",
      "7                      0.703297  0.175592  0.175592   9.0  \n",
      "8                      0.868056 -0.111389  0.111389   7.0  \n",
      "9                      0.871921  0.099269  0.099269   6.0  \n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "\n",
    "logistic_regression = result_df['Logistic Regression'].values\n",
    "knn = result_df['K-NN'].values\n",
    "\n",
    "diff = logistic_regression - knn\n",
    "abs_diff = np.abs(diff)\n",
    "ranks = pd.Series(abs_diff).rank()\n",
    "\n",
    "wilcoxon_result_df = pd.DataFrame({\n",
    "    'Dataset': result_df.index,\n",
    "    'ML1 Logistic Regression (Recall)': logistic_regression,\n",
    "    'ML2 K-NN Classifier (Recall)': knn,\n",
    "    'di': diff,\n",
    "    'Abs(di)': abs_diff,\n",
    "    'rank': ranks\n",
    "})\n",
    "\n",
    "stat, p_value = wilcoxon(logistic_regression, knn)\n",
    "\n",
    "print(f\"Wilcoxon signed-rank test statistic: {stat}, p-value: {p_value}\")\n",
    "print(wilcoxon_result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2619ce4b-9464-40b9-8dac-8711d374bdb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+------------------------------------+--------------------------------+------------+-----------+--------+\n",
      "|    | Dataset          |   ML1 Logistic Regression (Recall) |   ML2 K-NN Classifier (Recall) |         di |   Abs(di) |   rank |\n",
      "+====+==================+====================================+================================+============+===========+========+\n",
      "|  0 | poi-1.5.csv      |                           0.815714 |                       0.801418 |  0.0142958 | 0.0142958 |      1 |\n",
      "+----+------------------+------------------------------------+--------------------------------+------------+-----------+--------+\n",
      "|  1 | poi-2.0.csv      |                           1        |                       0.135135 |  0.864865  | 0.864865  |     10 |\n",
      "+----+------------------+------------------------------------+--------------------------------+------------+-----------+--------+\n",
      "|  2 | poi-2.5.csv      |                           0.850167 |                       0.907258 | -0.0570914 | 0.0570914 |      4 |\n",
      "+----+------------------+------------------------------------+--------------------------------+------------+-----------+--------+\n",
      "|  3 | poi-3.0.csv      |                           1        |                       0.903915 |  0.0960854 | 0.0960854 |      5 |\n",
      "+----+------------------+------------------------------------+--------------------------------+------------+-----------+--------+\n",
      "|  4 | velocity-1.4.csv |                           1        |                       0.945578 |  0.0544218 | 0.0544218 |      3 |\n",
      "+----+------------------+------------------------------------+--------------------------------+------------+-----------+--------+\n",
      "|  5 | velocity-1.5.csv |                           0.86619  |                       0.901408 | -0.035218  | 0.035218  |      2 |\n",
      "+----+------------------+------------------------------------+--------------------------------+------------+-----------+--------+\n",
      "|  6 | velocity-1.6.csv |                           0.471429 |                       0.602564 | -0.131136  | 0.131136  |      8 |\n",
      "+----+------------------+------------------------------------+--------------------------------+------------+-----------+--------+\n",
      "|  7 | lucene-2.0.csv   |                           0.878889 |                       0.703297 |  0.175592  | 0.175592  |      9 |\n",
      "+----+------------------+------------------------------------+--------------------------------+------------+-----------+--------+\n",
      "|  8 | lucene-2.2.csv   |                           0.756667 |                       0.868056 | -0.111389  | 0.111389  |      7 |\n",
      "+----+------------------+------------------------------------+--------------------------------+------------+-----------+--------+\n",
      "|  9 | lucene-2.4.csv   |                           0.97119  |                       0.871921 |  0.0992693 | 0.0992693 |      6 |\n",
      "+----+------------------+------------------------------------+--------------------------------+------------+-----------+--------+\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(wilcoxon_result_df, headers='keys', tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4a1bdc0-cd4b-42c2-b4e7-6b440af508c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Friedman test statistic: 6.962962962962957, p-value: 0.2234094054231663\n",
      "Do not Reject Null Hypothesis (There is no difference in the performance among 6 classifiers. )\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import friedmanchisquare\n",
    "\n",
    "decision_tree = result_df['Decision Tree'].tolist()\n",
    "logistic_regression = result_df['Logistic Regression'].tolist()\n",
    "naive_bayes = result_df['Naive Bayes'].tolist()\n",
    "random_forest = result_df['Random Forest'].tolist()\n",
    "knn = result_df['K-NN'].tolist()\n",
    "svm = result_df['SVM'].tolist()\n",
    "\n",
    "stat, p_value = friedmanchisquare(decision_tree, logistic_regression, naive_bayes, random_forest, knn, svm)\n",
    "print(f\"Friedman test statistic: {stat}, p-value: {p_value}\")\n",
    "\n",
    "alpha = 0.05\n",
    "if p_value < alpha: \n",
    "    print('Reject Null Hypothesis (At least two classifiers have significantly different performance)') \n",
    "else: \n",
    "    print('Do not Reject Null Hypothesis (There is no difference in the performance among 6 classifiers. )')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88c1a55-ac6d-4503-9ee8-8326afc88b21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
