{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c31705f8-41be-4200-9346-d9ca5f168dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c42bafa-c3fd-4fa3-b409-4780d3440e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [ \n",
    "    'poi-1.5.csv', \n",
    "    'poi-2.0.csv', \n",
    "    'poi-2.5.csv', \n",
    "    'poi-3.0.csv',\n",
    "    'velocity-1.4.csv',\n",
    "    'velocity-1.5.csv',\n",
    "    'velocity-1.6.csv',\n",
    "    'lucene-2.0.csv', \n",
    "    'lucene-2.2.csv', \n",
    "    'lucene-2.4.csv',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38852d17-7990-4cdd-83ed-660a4a50f900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisionTree(X,y):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X=scaler.transform(X)\n",
    "    X=pd.DataFrame(X)\n",
    "    features=X\n",
    "    label=y\n",
    "    #print(X)\n",
    "    # instantiate the model (using the default parameters)\n",
    "    dtreeclf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
    "    \n",
    "    scores = cross_validate(\n",
    "        estimator=dtreeclf, # model to evaluate\n",
    "        X=features, # inputs features\n",
    "        y=label, # output labels\n",
    "        cv=10, # how many folds\n",
    "        # list of model evaluation metrics\n",
    "        scoring=['accuracy', 'precision', 'recall'],\n",
    "    )\n",
    "\n",
    "    scores = pd.DataFrame(scores)\n",
    "    scores.round(4)\n",
    "    scores.mean().round(4)\n",
    "    return scores.mean()['test_recall']\n",
    "\n",
    "def logisticClassifier(X,y):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X=scaler.transform(X)\n",
    "    X=pd.DataFrame(X)\n",
    "    features=X\n",
    "    label=y\n",
    "    #print(X)\n",
    "    # instantiate the model (using the default parameters)\n",
    "    logreg = LogisticRegression(random_state=16)\n",
    "    \n",
    "    scores = cross_validate(\n",
    "        estimator=logreg, # model to evaluate\n",
    "        X=features, # inputs features\n",
    "        y=label, # output labels\n",
    "        cv=10, # how many folds\n",
    "        # list of model evaluation metrics\n",
    "        scoring=['accuracy', 'precision', 'recall'],\n",
    "    )\n",
    "    \n",
    "    scores = pd.DataFrame(scores)\n",
    "    scores.round(4)\n",
    "    scores.mean().round(4)\n",
    "    return scores.mean()['test_recall']\n",
    "\n",
    "def naiveBayesClassifier(X,y):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X=scaler.transform(X)\n",
    "    X=pd.DataFrame(X)\n",
    "    features=X\n",
    "    label=y\n",
    "    \n",
    "    # instantiate the model (using the default parameters)\n",
    "    NBclf = GaussianNB()\n",
    "    scores = cross_validate(\n",
    "        estimator=NBclf,  # model to evaluate\n",
    "        X=features,  # input features\n",
    "        y=label,  # output labels\n",
    "        cv=10,  # how many folds\n",
    "        # list of model evaluation metrics\n",
    "        scoring=['accuracy', 'precision', 'recall'],\n",
    "    )\n",
    "\n",
    "    scores = pd.DataFrame(scores)\n",
    "    scores.round(4)\n",
    "    scores.mean().round(4)\n",
    "    return scores.mean()['test_recall']\n",
    "\n",
    "def randomForest(X,y):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X=scaler.transform(X)\n",
    "    X=pd.DataFrame(X)\n",
    "    features=X\n",
    "    label=y\n",
    "    rfclassifier = RandomForestClassifier(random_state=59, n_jobs=-1, max_depth=5,\n",
    "    n_estimators=100, oob_score=True)\n",
    "    \n",
    "    scores = cross_validate(\n",
    "        estimator=rfclassifier, # model to evaluate\n",
    "        X=features, # inputs features\n",
    "        y=label, # output labels\n",
    "        cv=10, # how many folds\n",
    "        # list of model evaluation metrics\n",
    "        scoring=['accuracy', 'recall'],\n",
    "    )\n",
    "    \n",
    "    scores = pd.DataFrame(scores)\n",
    "    scores.round(4)\n",
    "    scores.mean().round(4)\n",
    "    return scores.mean()['test_recall']\n",
    "\n",
    "def knnClassifier(X, y):\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # Check data contiguity\n",
    "    if not X.flags.c_contiguous:\n",
    "        X = np.ascontiguousarray(X)\n",
    "    if not y.flags.c_contiguous:\n",
    "        y = np.ascontiguousarray(y)\n",
    "        \n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn.fit(X, y)\n",
    "    y_pred = knn.predict(X)\n",
    "    recall = metrics.recall_score(y, y_pred)\n",
    "    return recall\n",
    "\n",
    "\n",
    "def svmClassifier(X,y):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X=scaler.transform(X)\n",
    "    X=pd.DataFrame(X)\n",
    "    features=X\n",
    "    label=y\n",
    "    \n",
    "    # instantiate the model (using the default parameters)\n",
    "    svmclf = svm.SVC(kernel='linear', C=1, random_state=0)\n",
    "    scores = cross_validate(\n",
    "        estimator=svmclf,  # model to evaluate\n",
    "        X=features,  # input features\n",
    "        y=label,  # output labels\n",
    "        cv=10,  # how many folds\n",
    "        # list of model evaluation metrics\n",
    "        scoring=['accuracy','precision' , 'recall'],\n",
    "    )\n",
    "\n",
    "    scores = pd.DataFrame(scores)\n",
    "    scores.round(4)\n",
    "    scores.mean().round(4)\n",
    "    return scores.mean()['test_recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e39d17c1-614d-4e3a-a870-3838b918ed98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp5(dataset):\n",
    "    df = pd.read_csv(\"../dataset/\" + dataset)\n",
    "    df.dropna(inplace=True)\n",
    "    # print(f\"Dataset: {dataset} with shape {df.shape}\")\n",
    "    y = df.iloc[:,-1]\n",
    "    X = df.iloc[:,:-1]\n",
    "    \n",
    "    recall_scores = {\n",
    "        'Decision Tree': decisionTree(X, y),\n",
    "        'Logistic Regression': logisticClassifier(X, y),\n",
    "        'Naive Bayes': naiveBayesClassifier(X, y),\n",
    "        'Random Forest': randomForest(X, y),\n",
    "        'K-NN': knnClassifier(X, y),\n",
    "        'SVM': svmClassifier(X, y)\n",
    "    }\n",
    "    \n",
    "    return recall_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1455568f-2e92-4100-bd5f-84ebfd5f256f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Decision Tree  Logistic Regression  Naive Bayes  Random Forest      K-NN       SVM\n",
      "poi-1.5.csv            0.766667             0.815714     0.310952       0.850952  0.801418  0.794286\n",
      "poi-2.0.csv            1.000000             1.000000     1.000000       1.000000  0.135135  1.000000\n",
      "poi-2.5.csv            0.887167             0.850167     0.335667       0.879333  0.907258  0.834167\n",
      "poi-3.0.csv            1.000000             1.000000     1.000000       1.000000  0.903915  1.000000\n",
      "velocity-1.4.csv       1.000000             1.000000     1.000000       1.000000  0.945578  1.000000\n",
      "velocity-1.5.csv       0.723810             0.866190     0.311429       0.880000  0.901408  0.844762\n",
      "velocity-1.6.csv       0.546429             0.471429     0.271429       0.523214  0.602564  0.444643\n",
      "lucene-2.0.csv         1.000000             0.878889     1.000000       1.000000  0.703297  1.000000\n",
      "lucene-2.2.csv         0.689524             0.756667     0.400952       0.819524  0.868056  0.854286\n",
      "lucene-2.4.csv         1.000000             0.971190     1.000000       1.000000  0.871921  1.000000\n"
     ]
    }
   ],
   "source": [
    "result_df = pd.DataFrame()\n",
    "\n",
    "# Iterate over each dataset\n",
    "for dataset in datasets:\n",
    "    recall_scores = exp5(dataset)\n",
    "    df = pd.DataFrame.from_dict(recall_scores, orient='index', columns=[dataset])\n",
    "    result_df = pd.concat([result_df, df], axis=1)\n",
    "\n",
    "result_df = result_df.T\n",
    "print(result_df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "447f8343-a323-41e3-b899-10329c53aed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------------+-----------------------+---------------+-----------------+----------+----------+\n",
      "|                  |   Decision Tree |   Logistic Regression |   Naive Bayes |   Random Forest |     K-NN |      SVM |\n",
      "+==================+=================+=======================+===============+=================+==========+==========+\n",
      "| poi-1.5.csv      |        0.766667 |              0.815714 |      0.310952 |        0.850952 | 0.801418 | 0.794286 |\n",
      "+------------------+-----------------+-----------------------+---------------+-----------------+----------+----------+\n",
      "| poi-2.0.csv      |        1        |              1        |      1        |        1        | 0.135135 | 1        |\n",
      "+------------------+-----------------+-----------------------+---------------+-----------------+----------+----------+\n",
      "| poi-2.5.csv      |        0.887167 |              0.850167 |      0.335667 |        0.879333 | 0.907258 | 0.834167 |\n",
      "+------------------+-----------------+-----------------------+---------------+-----------------+----------+----------+\n",
      "| poi-3.0.csv      |        1        |              1        |      1        |        1        | 0.903915 | 1        |\n",
      "+------------------+-----------------+-----------------------+---------------+-----------------+----------+----------+\n",
      "| velocity-1.4.csv |        1        |              1        |      1        |        1        | 0.945578 | 1        |\n",
      "+------------------+-----------------+-----------------------+---------------+-----------------+----------+----------+\n",
      "| velocity-1.5.csv |        0.72381  |              0.86619  |      0.311429 |        0.88     | 0.901408 | 0.844762 |\n",
      "+------------------+-----------------+-----------------------+---------------+-----------------+----------+----------+\n",
      "| velocity-1.6.csv |        0.546429 |              0.471429 |      0.271429 |        0.523214 | 0.602564 | 0.444643 |\n",
      "+------------------+-----------------+-----------------------+---------------+-----------------+----------+----------+\n",
      "| lucene-2.0.csv   |        1        |              0.878889 |      1        |        1        | 0.703297 | 1        |\n",
      "+------------------+-----------------+-----------------------+---------------+-----------------+----------+----------+\n",
      "| lucene-2.2.csv   |        0.689524 |              0.756667 |      0.400952 |        0.819524 | 0.868056 | 0.854286 |\n",
      "+------------------+-----------------+-----------------------+---------------+-----------------+----------+----------+\n",
      "| lucene-2.4.csv   |        1        |              0.97119  |      1        |        1        | 0.871921 | 1        |\n",
      "+------------------+-----------------+-----------------------+---------------+-----------------+----------+----------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "print(tabulate(result_df, headers='keys', tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902209fa-e89c-4ec1-9c99-f11e99f346ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
